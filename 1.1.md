# requests 库
## 如何调用
```python
import requests
r = requests.get(url,params=None,**kargs)
```
`url` : 需要爬取的网页地址。

`params` :  

事实上，从 `get` 方法的源码可以看到，`get` 方法调用了 `requests` 库中的 `request` 方法。所以从本质上说，`requests` 库只有一个方法，那就是 `request` 方法，因为其他七个常用方法都是调用 request 方法。

r : `Response` 对象，包含了爬虫返回的所有内容。

## Response 对象的属性
常用的有五个属性：
- `status_code`
  
  HTTP 请求的返回状态，200 表示连接成功，404 表示失败。
  ```python
  print(r.status_code)
  ```

- `text`
  
  HTTP 响应内容的字符串形式。
  ```python
  print(r.text)
  ```

- `encoding`
  
  从 HTTP header 中猜测的相应内容编码方式。
  ```python
  print(r.encoding)
  ```

- `apparent_encoding`
  
  从内容中分析出的响应内容编码方式。
  ```python
  print(r.apparent_encoding)
  ```

- `content`
  
  HTTP 响应内容的二进制形式。

一般来讲，爬取完页面之后要通过 `status_code` 检查是否爬取成功。有时候通过  `r.text` 输出响应内容的字符串形式会产生乱码，可能是编码问题，可以通过如下方式解决：
```python
r.encoding = r.apparent_encoding
```
因为 `apparent_encoding` 是通过网页内容对编码方式进行分析的，而不是像 `encoding` 直接通过读取网页 `header` 中的 `charset` 字段来猜测编码方式的，所以它更加精确。

## Requests 库的常见异常
  